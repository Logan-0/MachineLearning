{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set imports\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA:\n",
    "University of California, School of Information and Computer Science.\n",
    "\n",
    "Source: Data Source: http://data.seoul.go.kr/\n",
    "SOUTH KOREA PUBLIC HOLIDAYS. URL: publicholidays.go.kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating A Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Mean Absolute Error <br>\n",
    "&emsp;&emsp;* Lets take all of the errors/residuals, sum the distance, take the average <br>\n",
    "&emsp;&emsp;* This says how far off we are <br>\n",
    "&emsp;&emsp;* $\\displaystyle \\Bigg[\\frac{\\sum \\limits _{i=1} ^{n} |y_{i} - \\hat{y_{i}}|}{n}\\Bigg]$ <br><br>\n",
    "\n",
    "2 - Mean Squared Error <br>\n",
    "&emsp;&emsp;* Same concept but to punish distance from linear model more harshly <br>\n",
    "&emsp;&emsp;* To do this we square the summation <br>\n",
    "&emsp;&emsp;* This is good for removing outliers as they will face a more intense value weighting. <br>\n",
    "&emsp;&emsp;* $\\displaystyle \\Bigg[\\frac{\\sum \\limits _{i=1} ^{n} |y_{i} - \\hat{y_{i}}|^{2}}{n}\\Bigg]$ <br><br>\n",
    "\n",
    "3 - Root Mean Squared Error <br>\n",
    "&emsp;&emsp;* Same concept but to punish distance from linear model more harshly <br>\n",
    "&emsp;&emsp;* To do this we square the summation <br>\n",
    "&emsp;&emsp;* This is good for more direct comparison to Y. The root mean squared provides an easier y comparion <br>\n",
    "&emsp;&emsp;* $\\displaystyle \\sqrt{\\Bigg[\\frac{\\sum \\limits _{i=1} ^{n} |y_{i} - \\hat{y_{i}}|^{2}}{n}\\Bigg]}$<br><br>\n",
    "\n",
    "4 - Coefficient of Determination <br>\n",
    "&emsp;&emsp;* RSS - Sum of Squared Residuals -> The Numerator in the Above Functions<br>\n",
    "&emsp;&emsp;* TSS - Total Sum of Squares<br><br>\n",
    "&emsp;&emsp;* TSS = $\\displaystyle \\sum \\limits _{i=1} ^{n} |y_{i} - \\bar{y_{i}}|^{2}$<br><br>\n",
    "&emsp;&emsp;* Notice Instead of predicted value '^' we use average/mean value '-'<br>\n",
    "&emsp;&emsp;* A value close to 0 with $R^{2}$ is a good indicator usually<br><br>\n",
    "&emsp;&emsp;* $R^{2} = 1 - \\Bigg[\\frac{RSS}{TSS}\\Bigg]$ <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Organization and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's name the columns\n",
    "dataset_cols = ['bike_count', 'hour', 'temp', 'humidity', 'wind', 'visibility', 'dew_pt_temp', 'radiation', 'rain', 'snow', 'functional']\n",
    "\n",
    "# To remove select columns add \"drop\", dropping... the date, holiday, and seasons columns, applying to columns axis\n",
    "df = pd.read_csv(\"DataSets/seoulBikeSharingDemand/SeoulBikeData.csv\").drop([\"Date\", \"Holiday\", \"Seasons\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name columns and remove hour, and make functional an on/off int value\n",
    "df.columns = dataset_cols\n",
    "df['functional'] = (df['functional'] == 'YES').astype(int)\n",
    "df = df[df['hour'] == 12]\n",
    "df = df.drop(['hour'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every label or category how does this effect bike count via scatter plot\n",
    "# The range listed is for making sure to not compare bike_count to bike_count so we skip 0\n",
    "# We stop short as functional is just an on/off value\n",
    "for label in df.columns[1:-1]:\n",
    "    plt.scatter(df[label], df['bike_count'])\n",
    "    plt.title(label)\n",
    "    plt.ylabel(\"Bike Count at Noon\")\n",
    "    plt.xlabel(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After deciding visually Wind, and Rain had too weak a correlation to have validity\n",
    "# We drop them and reprint the scatter plots.\n",
    "df = df.drop([\"wind\", \"visibility\"], axis=1)\n",
    "for label in df.columns[1:-1]:\n",
    "    plt.scatter(df[label], df['bike_count'])\n",
    "    plt.title(label)\n",
    "    plt.ylabel(\"Bike Count at Noon\")\n",
    "    plt.xlabel(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up a function to deal with defaults, single value, or no value operation\n",
    "def get_xy(dataframe, y_label, x_labels=None):\n",
    "    dataframe = copy.deepcopy(dataframe)\n",
    "    if x_labels is None:\n",
    "        X = dataframe[[c for c in dataframe.columns if c!= y_label]].values\n",
    "    else:\n",
    "        if len(x_labels) ==1:\n",
    "            X = dataframe[x_labels[0]].values.reshape(-1, 1)\n",
    "        else:\n",
    "            X = dataframe[x_labels].values\n",
    "\n",
    "    y = dataframe[y_label].values.reshape(-1,1)\n",
    "    data = np.hstack((X,y))\n",
    "\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with single value of temp. It may yield results based on visual perception\n",
    "dataArr_temp, X_train_temp, y_train_temp = get_xy(df, 'bike_count', x_labels=['temp'])\n",
    "dataArr_temp, X_val_temp, y_val_temp = get_xy(val, 'bike_count', x_labels=['temp'])\n",
    "dataArr_temp, X_test_temp, y_test_temp = get_xy(test, 'bike_count', x_labels=['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_reg = LinearRegression()\n",
    "temp_reg.fit(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Temperature Regression Coefficient: \" + str(temp_reg.coef_), \"Temperature Regression X-Intercept: \" + str(temp_reg.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R Squared (^2) Value: \" +str(temp_reg.score(X_test_temp, y_test_temp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not an Unrelated Result, but Also Not a Great Result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this Its a lot of little items. <br>\n",
    "1 - Create Scatter Plot Labeling Data Points. <br>\n",
    "2 - Create a Linear Regression Space from -20 -> 40 using 100 total values. <br>\n",
    "3 - Plot after using the linear regression to predict the u values; This must also be reshaped. <br>\n",
    "4 - Name the line, design and label the remaining information. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_temp, y_train_temp, label='Data', color='blue')\n",
    "x = tf.linspace(-20, 40, 100)\n",
    "plt.plot(x, temp_reg.predict(np.array(x).reshape(-1,1)), label='Fit', color='red', linewidth=3)\n",
    "plt.legend()\n",
    "plt.title(\"Bikes vs Temp\")\n",
    "plt.ylabel(\"Number of Bikes\")\n",
    "plt.xlabel(\"Temp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use all of the columns excluding out Y Label (Bike_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataArr, X_train_all, y_train_all = get_xy(df, 'bike_count', x_labels=df.columns[1:])\n",
    "dataArr, X_val_all, y_val_all = get_xy(val, 'bike_count', x_labels=df.columns[1:])\n",
    "dataArr, X_test_all, y_test_all = get_xy(test, 'bike_count', x_labels=df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reg = LinearRegression()\n",
    "all_reg.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R Squared (^2) Value: \" + str(all_reg.score(X_test_all, y_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sizable percentage improvement. Time for a Neural Net with only Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create layer to normalize the data; Only using temperature on this instance\n",
    "temp_normalizer = tf.keras.layers.Normalization(input_shape=(1, ), axis=None)\n",
    "temp_normalizer.adapt(X_train_temp.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using the normalizer, and only 1 dense layer\n",
    "# One dense layer makes the input linear\n",
    "# Making it a one node layer with no activation function makes it a linear output\n",
    "temp_nn_model = tf.keras.Sequential([\n",
    "    temp_normalizer,\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = temp_nn_model.fit(\n",
    "    X_train_temp.reshape(-1), y_train_temp,\n",
    "    verbose = 0,\n",
    "    epochs = 1000,\n",
    "    validation_data = (X_val_temp, y_val_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the previous Scatter Plot Creatin from ealier\n",
    "plt.scatter(X_train_temp, y_train_temp, label='Data', color='blue')\n",
    "x = tf.linspace(-20, 40, 100)\n",
    "plt.plot(x, temp_nn_model.predict(np.array(x).reshape(-1,1)), label='Fit', color='red', linewidth=3)\n",
    "plt.legend()\n",
    "plt.title(\"Bikes vs Temp\")\n",
    "plt.ylabel(\"Number of Bikes\")\n",
    "plt.xlabel(\"Temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very slight difference in the linear line drawn by neural net vs linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renormalization\n",
    "# Create layer to normalize the data; Only using temperature on this instance\n",
    "temp_normalizer = tf.keras.layers.Normalization(input_shape=(1, ), axis=None)\n",
    "temp_normalizer.adapt(X_train_temp.reshape(-1))\n",
    "\n",
    "# Create the model using the normalizer, and a full Neural Net\n",
    "nn_model = tf.keras.Sequential([\n",
    "    temp_normalizer,\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(\n",
    "    X_train_temp, y_train_temp,\n",
    "    validation_data=(X_val_temp, y_val_temp),\n",
    "    verbose=0,\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the previous Scatter Plot Creatin from ealier\n",
    "plt.scatter(X_train_temp, y_train_temp, label='Data', color='blue')\n",
    "x = tf.linspace(-20, 40, 100)\n",
    "plt.plot(x, nn_model.predict(np.array(x).reshape(-1,1)), label='Fit', color='red', linewidth=3)\n",
    "plt.legend()\n",
    "plt.title(\"Bikes vs Temp\")\n",
    "plt.ylabel(\"Number of Bikes\")\n",
    "plt.xlabel(\"Temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me now do this for every value/attribute/category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is what we can get by adding a layer\n",
    "all_normalizer = tf.keras.layers.Normalization(shape=(6, 1), axis=-1)\n",
    "all_normalizer.adapt(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using the normalizer, and a full Neural Net\n",
    "nn_model = tf.keras.Sequential([\n",
    "    all_normalizer,\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(\n",
    "    X_train_all, y_train_all,\n",
    "    validation_data=(X_val_all, y_val_all),\n",
    "    verbose=0,\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
